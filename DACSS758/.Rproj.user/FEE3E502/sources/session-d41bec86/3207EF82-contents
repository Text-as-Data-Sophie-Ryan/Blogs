---
title: "Text As Data Blog Posts "
format: html
editor: visual
---

# Blog Post 1

## Introduction

My name is Sophie Ryan, I am a Data Analytics and Computational Social Sciences graduate student with a background in Communications and Media Studies and Psychology. My studies have inspired a passion for learning about how people interact with each other and the world around them. I love using data as a way to deepen my understanding of the social sciences from a new perspective.

In my undergraduate degree, I took a course called Countercultural Films. I was able to learn about the counterculture movement of the 1960's through the perspective of media and music. I believe music is one of the most powerful forms of communication we have, and it is truly reflective of social attitudes. During this time, rock music was extremely politically charged and played a huge role in giving young people a voice. After Kennedy's assassination, this political and cultural phenomenon spread anti-war, anti-establishment, and pro-peace messages through music and film. The pinnacle of this movement was the Woodstock Festival in 1969, where influential artists like Jimi Hendrix, Bob Dylan, and Joan Baez gave legendary performances that protested the government and promoted social justice. Hundreds of thousands of people came together at the festival to show solidarity. Moments like this display how important music can be in politics and culture. It acted not just as entertainment, but a catalyst for change and representation of public opinion.

## Research Question

My goal is to dive deeper into this political and social movement through the lense of text-as-data. How did the sentiment and themes of counterculture rock music differ from the mainstream political messages from the United States government, particularly in relation to the Vietnam War, social justice, and civil rights?

## Corpora

The corpora I plan to use for the music portion of this project will come from the Billboard Charts and Lyric Genius APIs. This will allow me to see the most popular and influential music, and access the lyrics to those songs to conduct further analysis. MSU's underground press and alternative newspaper collection could be used as a supplemental source representative of the counterculture movement's messages.

For my analysis of mainstream political messages from the time, I will use ProQuest's archives of historical newspapers. Additionally, I will investigate the Miller Center UVA speech archive, which provides transcripts of presidential speeches.

## Wrapping Up

I'm looking forward to using text analysis to dive deeper into how music was representative of the political and social unrest of the 1960's. Many of the lyrics from these artists openly criticized the government, the war, and racial injustice. The Lyric Genius corpora will be a great source for identifying themes, sentiments, and word frequencies. Mainstream newspaper articles will show how politics were being presented. Presidential speeches are also a good representation of the messages that the government was trying to convey at the time. I'm very intrigued to see the contrast of sentiments and themes between the two opposing groups. It could provide insight as to how the counterculture movement was so influential and worked to change public opinion on a variety of issues.

# Blog Post 2

# Counterculture: Music vs. Media

## Research Question

In my project, I will be investigating how themes and sentiments of counterculture rock music in the 1960's compared to that of mainstream media, particularly in relation to the Vietnam War, civil rights, and social justice movements.

## My Corpus

In order to collect this data, I decided to utilize the set list from the Woodstock Art and Music Festival of 1969. This festival was a pivotal moment in music history and popular culture. It was representative of the wide social unrest taking place at the time. Almost 500,000 people attended in efforts to promote peace and unity. This was the pinnacle of the counterculture movement, a political and cultural phenomenon that was anti-war, anti-establishment, and pro-peace. Young people across the country organized protests to fight for civil rights, and music often played a huge role in this. Many rock artists at this time used their platforms to support these causes, and the music was very politically charged. Jimi Hendrix' famous rendition of the Star Spangled Banner is one example of how the festival was leveraged to express unhappiness with the political climate. Therefore, the music played at this 3 day long festival is the perfect culmination of songs for my corpus representing the messages of counterculture's rock music.

### Lyrics Corpus

To acquire these songs and lyrics, I used webscraping from Wikipedia and a lyric website called LyricsFreak. First, I scraped the Wikipedia page that gave a list of songs and artists.

```{r}
#Loading packages
library(rvest)
library(dplyr)
library(stringr)
library(purrr)
library(dplyr)
library(quanteda.textplots)
library(quanteda.sentiment)

#Defining the Wikipedia URL for the setlist at Woodstock
url1 <- "https://en.wikipedia.org/wiki/List_of_performances_and_events_at_Woodstock_Festival"

#Defining the CSS selectors. 
css_selector <- ".mw-body p + ol"
css_selector_artists <- ".mw-body .mw-heading3"
special_css <- "ol"
```

I defined 3 selectors, one for the titles which gave the artist name, another for the body which gave the song list, and a third for a special case, Crosby Stills and Nash. This artist's songs were in a nested list, which I had to treat differently.

```{r}
#Song text
song_list <- url1 %>%
  read_html() %>%
  html_nodes(css = css_selector) %>%
  html_text()
  
#CSN song text
special_case <- url1 %>%
  read_html() %>%
  html_nodes(css = special_css) %>%
  html_text() 

#Artist list
artist_list <- url1 %>%
  read_html() %>%
  html_nodes(css = css_selector_artists) %>%
  html_text()

#Removing a speaker, not an artist
artist_list <- artist_list[-2]

#Defining the nested list I need
special2 <- (special_case[29:32])
flattened_songs <- paste(special2, collapse = "\n")

#Adding the nested list songs to the original song list in the corresponding artist spot
song_list <- append(song_list, list(flattened_songs), after = 28)

# Remove [edit] from the artist names
artist_list <- gsub("\\[edit\\]", "", artist_list)
artist_list <- str_squish(artist_list)

split_songs <- str_split(song_list, "\n")

# Clean up whitespace and remove empty rows
clean_songs <- map(split_songs, ~ str_squish(.x) %>% .[. != ""])

# Only keep artists with corresponding song lists
# Check which artists actually have songs listed
valid_artists <- artist_list[1:length(clean_songs)]

# Combine only valid pairs
woodstock_data <- map2(
  valid_artists,
  clean_songs,
  ~ data.frame(artist = .x, song = .y, stringsAsFactors = FALSE)
) %>%
  bind_rows()

# Display the first 10 rows
head(woodstock_data, 10)
```

Now I have a data frame consisting of every artist and each song they played. Next, I had to add lyrics to the data frame. I did this by creating a function that scraped the lyrics from pages on LyricsFreak for every song.

```{r}
#Loading packages
library(httr)
library(curl)

#Creating a function to scrape the LyricsFreak pages for each song. 
get_lyrics_lyricsfreak <- function(song_name, artist_name) {
  # Construct search URL
  base_search_url <- "https://www.lyricsfreak.com/search.php"
  query <- paste(artist_name, song_name)
  
  # Send search request
  search_page <- GET(base_search_url, query = list(q = query))
  
  # Parse the search result page
  search_html <- read_html(content(search_page, as = "text"))
  
  # Get the first song link that matches the artist
  song_link <- search_html %>%
    html_nodes("a.song") %>%
    html_attr("href") %>%
    .[1]  # Get the first match
  
  # If no link found, return NA
  if (is.na(song_link) || length(song_link) == 0) {
    return(NA)
  }
  
  # Complete the URL for the song's page
  song_url <- paste0("https://www.lyricsfreak.com", song_link)
  
  # Scrape the lyrics from the song's page
  song_page <- read_html(song_url)
  
  lyrics <- song_page %>%
    html_nodes(".js-share-text") %>%
    html_text2()
  
  # Clean up the lyrics text
  lyrics <- str_squish(lyrics)
  
  return(lyrics)
}


# Initialize a column to store lyrics
woodstock_data$lyrics <- NA

# Loop through each row and get lyrics
for (i in 1:nrow(woodstock_data)) {
  song_name <- woodstock_data$song[i]
  artist_name <- woodstock_data$artist[i]
  
  # Get the lyrics and store it in the new column
  woodstock_data$lyrics[i] <- get_lyrics_lyricsfreak(song_name, artist_name)
  
  # Pause to be polite to the website
  Sys.sleep(2)
}
```

```{r}
head(woodstock_data)
```

Running this function added an empty column to my existing data frame, and added the lyrics for each song. I am running into some problems at this step, as 161 of the songs do not have lyrics. Going forward, I may have to scrape from other websites to fill in gaps. For now, I have enough lyrics to create a lyrics corpus and perform some pre-processing steps.

```{r}
#First I removed NA and missing values 
cleaned_data <- woodstock_data %>%
  filter(!is.na(lyrics) & lyrics != "")

cleaned_data$doc_id <- paste(cleaned_data$artist, cleaned_data$song, sep = " - ")

#Creating the corpus
lyrics_corpus <- corpus(cleaned_data$lyrics, 
                        docnames = cleaned_data$doc_id)

summary(lyrics_corpus)
ndoc(lyrics_corpus)
sum(ntoken(lyrics_corpus))
```

There are 146 documents and 31958 tokens in my corpus.

Next, I removed numbers, punctuation, and stopwords. I added some custom stopwords, as song lyrics tend to have some repetitive terms that are not very representative of the messages of the songs.

```{r}
tokens_clean <- tokens(lyrics_corpus, 
                       what = "word", 
                       remove_numbers = TRUE,
                       remove_punct = TRUE) %>%
                tokens_tolower()

custom_stopwords <- c(stopwords("en"), "baby", "na", "lyrics", "oh", "got", "x", "yeah", "can", "go", "like", "now", "chorus", "get", "one", "x")

tokens_clean <- tokens_select(tokens_clean,
                              pattern = custom_stopwords,
                              selection = "remove")
```

Then, I created a document feature matrix and found some top features.

```{r}
lyrics_dfm <- dfm(tokens_clean)
topfeatures(lyrics_dfm)
```

Next, I created a few preliminary visualizations to get an idea of what I'll be working with. I made a wordcloud and a network. Moving forward, I'll have to figure out ways I can remove more custom "stopwords" that appear in almost all songs but do not add value.

```{r}
library(quanteda.textplots)

set.seed(1234)

# draw the wordcloud
textplot_wordcloud(lyrics_dfm, min_count = 20, random_order = FALSE)
```

```{r}
smaller_dfm <- dfm_trim(lyrics_dfm, min_termfreq = 10)
smaller_dfm <- dfm_trim(smaller_dfm, min_docfreq = .2, docfreq_type = "prop")

# create fcm from dfm
smaller_fcm <- fcm(smaller_dfm)

# check the dimensions (i.e., the number of rows and the number of columnns)
# of the matrix we created
dim(smaller_fcm)

myFeatures <- names(topfeatures(smaller_dfm, 30))

# retain only those top features as part of our matrix
even_smaller_fcm <- fcm_select(smaller_fcm, pattern = myFeatures, selection = "keep")

# check dimensions
dim(even_smaller_fcm)

# compute size weight for vertices in network
size <- log(colSums(even_smaller_fcm))

# create plot
textplot_network(even_smaller_fcm, vertex_size = size / max(size) * 3)
```

Finally I found some sentiment scores.

```{r}
sentiment_scores <- dfm_lookup(lyrics_dfm, dictionary = data_dictionary_LSD2015)

# convert to df
sentiment_df <- convert(sentiment_scores, to = "data.frame")

sentiment_df$Text <- as.character(lyrics_corpus)

head(sentiment_df)
```

There is still a lot of work that needs to be done on this corpus, but I believe I'm making good progress and this will be a good representation of the themes of counterculture music.

### Media Corpus

For my corpus of mainstream media about counterculture, I would like to use historical newspapers from ProQuest. I was exploring many of these documents using search terms such as "Vietnam War", "antiwar", "protest", "hippie", "counterculture", etc. There were hundreds of relevant documents. Unfortunately, most of these are in pdf form. This makes creating the corpus more difficult. Going forward, I will either have to perform OCR, or find another source to represent the sentiment of mainstream media during the 60's.

Here's an example of one newspaper article from April 24, 1971.

![](images/Screenshot 2025-02-26 at 5.01.13 PM.png)

Documents like this could be really useful in my analysis, and I look forward to continuing work on creating a corpus.

## Conclusion

Using text as data to investigate counterculture will provide a really interesting snapshot of sentiments and themes of the time period. I'm fascinated by this movement, and I believe it was a very important time in America for politics, culture, and rock music. Breaking down these corpora into their core elements can provide a new perspective on counterculture that I haven't previously considered, and I'm excited to see where this project can take me.
